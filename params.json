{"name":"UFITS","tagline":"Fungal ITS Clustering using USEARCH","body":"# UFITS\r\n###USEARCH Fungal ITS Clustering:###\r\n\r\nUFITS is a series of scripts to process fungal ITS amplicon data using USEARCH8\r\n___\r\n\r\n<img src=\"https://github.com/nextgenusfs/ufits/blob/master/docs/ufits.png\" width=\"400\">\r\n\r\n\r\n####Installation:####\r\n\r\n* [Mac install instructions](docs/mac_install.md)\r\n* [Ubuntu install instructions](docs/ubuntu_install.md)\r\n* [Windows install instuructions](docs/windows_install.md)\r\n\r\n\r\n####UFITS Wrapper script####\r\n\r\nUFITS comes with a wrapper script for ease of use.  On UNIX, you can call it by simply typing `ufits`, while on windows you need to type `ufits.py` (unless you have put the .py extension in your PATHEXT, directions [here](http://stackoverflow.com/a/13023969/4386003)).\r\n\r\n```\r\n$ ufits.py\r\nUsage:      ufits <command> <arguments>\r\nversion:    0.2.1\r\n    \r\nCommand:    ion         pre-process Ion Torrent data (find barcodes, remove primers, trim/pad)\r\n            illumina    pre-process folder of de-multiplexed Illumina data (gunzip, merge PE, remove primers, trim/pad)\r\n            cluster     cluster OTUs (using UPARSE algorithm)\r\n            filter      OTU table filtering\r\n            taxonomy    Assign taxonomy to OTUs      \r\n            heatmap     Create heatmap from OTU table\r\n\r\nSetup:      download    Download Reference Databases\r\n            database    Format Reference Databases for Taxonomy\r\n            \r\nWritten by Jon Palmer (2015) nextgenusfs@gmail.com\r\n```\r\n\r\nAnd then by calling one of the commands, you get a help menu for each:\r\n\r\n```\r\n$ ufits.py cluster\r\nUsage:      ufits cluster <arguments>\r\nversion:    0.2.1\r\n    \r\nArguments:  -i, --fastq         Input FASTQ file (Required)\r\n            -o, --out           Output base name. Default: out\r\n            -e, --maxee         Expected error quality trimming. Default: 1.0\r\n            -p, --pct_otu       OTU Clustering Radius (percent). Default: 97\r\n            -m, --minsize       Minimum size to keep (singleton filter). Default: 2\r\n            -l, --length        Length to trim reads. Default 250\r\n            --mock              Name of spike-in mock community. Default: None\r\n            --mc                Mock community FASTA file. Default: ufits_mock3.fa\r\n            --uchime_ref        Run Chimera filtering. Default: off [ITS1, ITS2, Full]\r\n            --map_unfiltered    Map unfiltered reads back to OTUs. Default: off\r\n            --unoise            Run De-noising pre-clustering (UNOISE). Default: off\r\n            --size_annotations  Append size annotations to OTU names. Default: off\r\n            -u, --usearch       USEARCH executable. Default: usearch8\r\n            \r\nWritten by Jon Palmer (2015) nextgenusfs@gmail.com\r\n\r\n```\r\n\r\n####Processing Ion Torrent Data:####\r\n\r\nFrom the Torrent Server, analyze the data using the `--disable-all-filters` BaseCaller argument.  This will leave the adapters/key/barcode sequence intact.  The data need to be exported as a FASTQ file, or alternatively use a 3rd party tool to convert the BAM output file to FASTQ (i.e. `bedtools bamtofastq -i <BAM> -fq <FASTQ>`).  You can then de-multiplex the data as follows:\r\n\r\n```\r\nufits ion --barcodes 1,5,24 -i data.fastq -o data\r\n```\r\n\r\nThis will find Ion barcodes (1, 5, and 24) and relabel header with that information (barcodelabel=BC_5;). By default, it will look for all 96 Ion Xpress barcodes, specifiy the barcodes you used by a comma separated list. Next the script will find and trim both the forward and reverse primers (default is ITS2 region: fITS7 & ITS4), and then finally will trim or pad with N's to a set length (default: 250 bp).  Trimming to the same length is critcally important for USEARCH to cluster correctly, padding with N's after finding the reverse primer keeps short ITS sequences from being discarded.  These options can be customized using: `--fwd_primer`, `--rev_primer`, `--trim_len`, etc.\r\n\r\n####Processing Illumina MiSeq PE Data:####\r\n\r\nPaired-end MiSeq data is typically delivered already de-multiplexed into separate read files, that have a defined naming structure from Illumina that looks like this: \r\n\r\n```\r\n<sample name>_<barcode sequence>_L<lane (0-padded to 3 digits)>_R<read number>_<set number (0-padded to 3 digits>.fastq.gz\r\n```\r\n\r\nYou can processes a folder of Illumina data like this:\r\n\r\n```\r\nufits illumina -i folder_name\r\n```\r\n\r\nThis will find all files ending with '.fastq.gz' in the input folder, gunzip the files, and then sequentially process the paired read files.  First it will run USEARCH8 `-fastq_mergepairs`, however, since some ITS sequences are too long to overlap you can rescue longer sequences by recovering the the non-merged forward reads.  Alternatively, you can only utilize the forward reads (R1), by passing the `--reads forward` argument.  Next the forward and reverse primers are removed and the reads are trimmed/padded to a set length of clustering. Finally, the resulting FASTQ files for each of the processed samples are concatenated together into a file called `ufits.demux.fq` that will be used for the next clustering step.  The script will also output a text file called `ufits-filenames.txt` that contains a tab-delimited output of the sample name as well as [i5] and [i7] index sequences that were used.\r\n\r\n####OTU Clustering:####\r\n\r\nNow the data from either platform (Ion or Illumina) can be clustered by running the following:\r\n\r\n```\r\nufits cluster -i ufits.demux.fq -o ion --mock BC_5\r\n```\r\n\r\nThis will run `usearch -fastq_filter` to filter the data based on expected errors, then remove duplicated sequences, sort the output by frequency, and finally `usearch -cluster_otus`.  You can also optionally run UCHIME Reference filtering by adding the `--uchime_ref ITS2` option or change the default clustering radius (97%) by passing the `--pct_otu` option. Another option is to process a spike-in control or mock community, you can specify a barcode name for the mock community by passing in `--mock BC_5` which will run some additional steps and report stats of the run to STDOUT.  Type `-h` for all the available options.\r\n\r\n\r\n####OTU Table Filtering####\r\n\r\nThe data may need some additional filtering if you included a spike-in control mock community.  The advantage is that you know what should be in the spike-in control barcode sample, thus you can modify USEARCH8 clustering parameters that give you reasonable results.  If you need to trim your OTU table by some threshold, i.e. several OTUs at low abundance are showing up in your spike-in control sample that represent contamination or sequence error - you can set a threshold and filter the OTU table. This is done with the following script:\r\n\r\n```\r\nufits filter -i test.otu_table.txt -b BC_27\r\n```\r\n\r\nThis  will read the OTU table `-i`, count the number of OTUs in the barcode specified by the `-b` parameter and give you some basic stats to STDOUT.  It will then ask for a value to threshold trim the data, if you would type in a value of 2, then 2 will be subtracted from every column and a new OTU table will be saved to file ending in `.filteredX.out_table.txt` as well as a new OTU fasta file `filtered.otus.fa`.  To combat 'barcode switching' or 'index bleed', an additional filter can be run that removes OTU counts that are less than 0.1% of the total for each OTU.  If you used dual indexing on MiSeq and have a lot of indexes that were re-used, you will need to increase this filter to at least 0.5, by passing the argument `-p 0.5` to the script.  Finally, this script will remove the mock spike in control sample from your dataset - as it should not be included in downstream processing.\r\n\r\nIf you do not have a mock community spike in, you can still run the index bleed filter by just running the command without a `-b` argument, such as:\r\n\r\n```\r\nufits filter -i test.otu_table.txt --index_bleed 0.5\r\n```\r\n\r\n\r\n####Assign Taxonomy:####\r\n\r\nYou can assign taxonomy to your OTUs using UFITS, either using UTAX from USEARCH8.1 or using usearch_global.  The databases require some initial setup before you can use the `ufits taxonomy` command.  The following will get you setup with the UNITE database:\r\n\r\n```\r\n#download the UNITE public release\r\nufits download -i unite\r\n\r\n#Now trim priming sites and reformat FASTA headers for compatibility with UTAX\r\nufits database -i sh_dynamic_01.08.2015.fasta -o UNITE --create_db utax\r\n```\r\n\r\nThese two commands will download the newest UNITE curated ITS database.  Then the script will reformat the UNITE headers to be compatible with UTAX classifier training as well as trim the reference database to correspond to the region that you sequenced, i.e. ITS2, based on primers used.  Finally, UFITS will use the re-formatted reference to train the classifier.  The resulting database is stored in the `DB` folder of the `ufits` directory.  \r\n\r\nIssuing the `ufits taxonomy` command will inform you which databases have been properly configured:\r\n\r\n```\r\n$ ufits taxonomy\r\nUsage:      ufits taxonomy <arguments>\r\nversion:    0.2.2\r\n    \r\nArguments:  -i, --fasta         Input FASTA file (i.e. OTUs from ufits cluster) (Required)\r\n            -o, --out           Base name for output file. Default: ufits-taxonomy.<method>.txt\r\n            -m, --method        Taxonomy method. Default: utax [utax, usearch, blast] (Required)\r\n            -d, --db            Database (must be in UDB format).\r\n            --append_taxonomy   OTU table to append taxonomy. Default: none\r\n            --utax_cutoff       UTAX confidence value cutoff. Default: 0.8 [0 to 0.9]\r\n            -u, --usearch       USEARCH executable. Default: usearch8\r\n\r\nDatabases Configured: \r\nDB_name                       FASTA originated from         Fwd Primer                    Rev Primer                    Records                      \r\nUNITE.utax.udb                sh_dynamic_01.08.2015.fasta   GTGARTCATCGAATCTTTG           TCCTCCGCTTATTGATATGC          39892                        \r\nUNITE_INSD.usearch.udb        UNITE_public_01.08.2015.fasta GTGARTCATCGAATCTTTG           TCCTCCGCTTATTGATATGC          373101                       \r\n            \r\nWritten by Jon Palmer (2015) nextgenusfs@gmail.com  \r\n```\r\n\r\nAnd then you can use the `ufits taxonomy` command to assign taxonomy to your OTUs as well as append them to your OTU table as follows:\r\n\r\n```\r\nufits taxonomy -i data.filtered.otus.fa -m utax -d UNITE.utax.udb --append_taxonomy\r\n```\r\n\r\n####Dependencies####\r\n* Python 2\r\n* Biopython\r\n* USEARCH8 (to use UTAX you will need at least version 8.1.1756)\r\n\r\nPython and USEARCH need to accessible in PATH; alternatively you can pass in the variable `-u /path/to/usearch8` to scripts requiring USEARCH8.  In order to draw a heatmap using `ufits.py heatmap` you will need to have the following python libraries installed: `matplotlib, pandas, numpy`.  They can be installed with pip, i.e. `pip install matplotlib pandas numpy`.","google":"","note":"Don't delete this file! It's used internally to help with page regeneration."}